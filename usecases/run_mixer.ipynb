{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c8affae",
   "metadata": {},
   "source": [
    "# Run MiXeR\n",
    "\n",
    "Convenience notebook to run multiple sets of summary stats through MiXeR with handling of Slurm job dependencies.\n",
    "\n",
    "## Using\n",
    "To use, start jupyter from a machine which can submit jobs using Slurm (e.g., TSD `pXXX-appn-norment01`, or `pXXX-submit` nodes - replace `pXXX` with the project id below). \n",
    "An ssh tunnel must exist at a given port (here `8888`):\n",
    "\n",
    "```\n",
    "# on pXXX-appn-norment01:\n",
    "jupyter notebook --no-browser --port=8888 (This command is for VM ware Horizon users) \n",
    "# (when the given port is busy due to previous sessions, try another port and change accordingly in the below command)\n",
    "\n",
    "# directly on the login node: \n",
    "ssh -N -f -L localhost:8888:localhost:8888 $USER@pXXX-appn-norment01\n",
    "# (This command is for thin link users)\n",
    "\n",
    "# open your browser and connect to (or URL printed to terminal when starting jupyter notebook)\n",
    "localhost:8888\n",
    "```\n",
    "\n",
    "The ssh tunnel step (`ssh -N -f -L ...`) may be omitted on other systems than TSD. \n",
    "\n",
    "NOTE: This code does not check for existing file output and may overwrite files already present in \n",
    "output dirs (`sumstats_mixer`, `logs`, `results`, `jobs`)\n",
    "\n",
    "NOTE: There is a jupyter/jupyterlab installation in the `mixer.sif` container, but this does not expose the host's `sbatch` command required to submit jobs.\n",
    "Start jupyter from the host machine instead, and install it if is missing (e.g., `pip install jupyter`) or load the corresponding module (`module load JupyterLab/3.5.0-GCCcore-11.3.0`) before invoking `jupyter notebook ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import subprocess as sp\n",
    "import datetime\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7dfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some common job params (modify as needed)\n",
    "account = 'p33_norment'  # project account on TSD p33. 'p697_norment' on p697. Modify as needed\n",
    "mixer_dir = '/ess/p33/cluster/github/comorment/mixer'  # path to clone of repository. \n",
    "# The above is for p33, should be '/ess/p697/data/durable/s3-api/github/comorment/mixer' on p697\n",
    "singularity_module = 'singularity/3.7.1'  # module for singularity, modify as needed\n",
    "cpus_per_task = 16  # number of CPUs per task\n",
    "mem_per_cpu = '8000M'  # memory per CPU in MB\n",
    "array = '1-2'  # NOTE: use '1-20' for production runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input files (assuming all are present in \"traitfolder\" directory).\n",
    "# Can also be an absolute path.\n",
    "# traitfolder = '/REF/sumstats'  # if running using jupyterlab in mixer.sif container\n",
    "traitfolder = os.path.join(mixer_dir, 'reference', 'sumstats')\n",
    "\n",
    "# Define primary and secondary traits. \n",
    "# It is possible to include multiple traits/files in each dictionary,\n",
    "# which will allow running for with multiple traits. \n",
    "# Caution should be taken if the same traits/files exist in both dictionaries,\n",
    "# as same vs same will be omitted\n",
    "primary_traits = {\n",
    "    'SCZ': 'clozuk_pgc2.meta.sumstats.txt.gz'\n",
    "}\n",
    "\n",
    "secondary_traits = {\n",
    "    'INT': 'SavageJansen_2018_intelligence_metaanalysis.txt.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output directories\n",
    "output_dir = os.path.join('.', 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "jobscripts_dir = os.path.join('.', 'jobscripts')\n",
    "os.makedirs(jobscripts_dir, exist_ok=True)\n",
    "\n",
    "logs_dir = os.path.join('.', 'logs')\n",
    "os.makedirs(logs_dir, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45aa4e2e",
   "metadata": {},
   "source": [
    "### Prep input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some sumstats columns. \n",
    "# Need ['SNP', 'CHR', 'BP', 'A1', 'A2', 'N', 'Z']\n",
    "sumstats_mixer = 'sumstat_mixer'\n",
    "os.makedirs(sumstats_mixer, exist_ok=True)\n",
    "\n",
    "mixercols = ['SNP', 'CHR', 'BP', 'A1', 'A2', 'N', 'Z']\n",
    "# map columns to mixercols (edit as necessary)\n",
    "mapper = {\n",
    "    'RSID': 'SNP',\n",
    "    'POS': 'BP',\n",
    "    'EffectAllele': 'A1',\n",
    "    'OtherAllele': 'A2',\n",
    "    'Zscore': 'Z',\n",
    "    'N_analyzed': 'N',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert files for MiXer (in parallel). May take a few minutes.\n",
    "def process_sumstats(num_cores=2):\n",
    "    def _process_sumstats(fname):\n",
    "        print(f'processing {fname}')\n",
    "        df = pd.read_csv(os.path.join(traitfolder, fname), delim_whitespace=True, low_memory=False)\n",
    "        df.rename(columns=mapper, inplace=True)\n",
    "\n",
    "        # fill in some missing info\n",
    "        if fname == 'clozuk_pgc2.meta.sumstats.txt.gz':\n",
    "            df['N'] = 4 / (1 / 40675 + 1 / 64643)\n",
    "            df['Z'] = -st.norm.ppf(df['P'].values*0.5)*np.sign(df['OR'].values - 1).astype(np.float64)\n",
    "\n",
    "\n",
    "        for col in mixercols:\n",
    "            assert col in df.columns, f'col {col} is missing in {fname}'\n",
    "        \n",
    "        # make sure that all are upper case\n",
    "        df['A1']=df['A1'].str.upper()\n",
    "        df['A2']=df['A2'].str.upper()\n",
    "\n",
    "        # MHC region:\n",
    "        chr_6_mhc = (df['CHR'] == 6) & (df['BP'] > 26e6) & (df['BP'] < 34e6)\n",
    "        \n",
    "        # drop X chrom.\n",
    "        # mixer crash on sumstats lines with CHR=X\n",
    "        chr_X = df['CHR'] == 'X' \n",
    "        \n",
    "        # and or\n",
    "        exclude = chr_6_mhc | chr_X\n",
    "\n",
    "        assert exclude.sum() == (chr_6_mhc.sum() + chr_X.sum()), 'mismatch in excluded positions'\n",
    "        \n",
    "        # save\n",
    "        df.loc[~exclude, mixercols].to_csv(os.path.join(sumstats_mixer, fname), index=False, sep='\\t')\n",
    "    \n",
    "\n",
    "    return Parallel(n_jobs=num_cores)(delayed(_process_sumstats)(fname) for fname in {**primary_traits, **secondary_traits}.values())\n",
    "\n",
    "_ = process_sumstats(num_cores=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "256202d4",
   "metadata": {},
   "source": [
    "### Define jobscript contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic SLURM header. Modify as needed.\n",
    "slurm_header = '''#!/bin/sh\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --account={account}\n",
    "#SBATCH --open-mode=truncate\n",
    "#SBATCH --output={log_file}\n",
    "#SBATCH --error={log_file}\n",
    "#SBATCH --time={time}\n",
    "#SBATCH --cpus-per-task={cpus_per_task}\n",
    "#SBATCH --mem-per-cpu={mem_per_cpu}\n",
    "#SBATCH --array={array}\n",
    "\n",
    "module purge\n",
    "module load {singularity_module}\n",
    "\n",
    "export MIXER={mixer_dir}\n",
    "export SINGULARITY_BIND=\"$MIXER/reference:/REF:ro\"\n",
    "export SIF=$MIXER/singularity\n",
    "export MIXER_COMMON_ARGS=\"--ld-file /REF/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.@.run4.ld --bim-file /REF/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.@.bim --threads 16\"\n",
    "export REP=\"rep${{SLURM_ARRAY_TASK_ID}}\"\n",
    "export EXTRACT=\"--extract /REF/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.prune_maf0p05_rand2M_r2p8.$REP.snps\"\n",
    "\n",
    "export PYTHON=\"singularity exec --home=$PWD:/home --cleanenv $SIF/mixer.sif python\"\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 = '''\n",
    "$PYTHON /tools/mixer/precimed/mixer.py fit1 $MIXER_COMMON_ARGS $EXTRACT \\\n",
    "    --trait1-file {} \\\n",
    "    --out {}/{}.fit.$REP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 = '''\n",
    "$PYTHON /tools/mixer/precimed/mixer.py fit2 $MIXER_COMMON_ARGS $EXTRACT \\\n",
    "    --trait1-file {} \\\n",
    "    --trait2-file {} \\\n",
    "    --trait1-params {}/{}.fit.$REP.json --trait2-params {}/{}.fit.$REP.json \\\n",
    "    --out {}/{}_vs_{}.fit.$REP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = '''\n",
    "$PYTHON /tools/mixer/precimed/mixer.py test1 $MIXER_COMMON_ARGS \\\n",
    "    --trait1-file {} \\\n",
    "    --load-params {}/{}.fit.$REP.json \\\n",
    "    --out {}/{}.test.$REP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = '''\n",
    "$PYTHON /tools/mixer/precimed/mixer.py test2 $MIXER_COMMON_ARGS \\\n",
    "    --trait1-file {} \\\n",
    "    --trait2-file {} \\\n",
    "    --load-params {}/{}_vs_{}.fit.$REP.json \\\n",
    "    --out {}/{}_vs_{}.test.$REP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine1 = '''$PYTHON /tools/mixer/precimed/mixer_figures.py combine \\\n",
    "    --json {output_dir}/{trait}.{fit_or_test}.rep@.json  \\\n",
    "    --out {output_dir}/{trait}.{fit_or_test}'''\n",
    "combine2 = '''$PYTHON /tools/mixer/precimed/mixer_figures.py combine \\\n",
    "    --json {output_dir}/{trait0}_vs_{trait1}.{fit_or_test}.rep@.json  \\\n",
    "    --out {output_dir}/{trait0}_vs_{trait1}.{fit_or_test}'''\n",
    "fig_one = '''$PYTHON /tools/mixer/precimed/mixer_figures.py one \\\n",
    "    --json {output_dir}/{trait0}.{fit_or_test}.json {output_dir}/{trait1}.{fit_or_test}.json \\\n",
    "    --out {output_dir}/{trait0}_and_{trait1}.{fit_or_test} \\\n",
    "    --trait1 {trait0} {trait1} --statistic mean std --ext {ext}'''\n",
    "\n",
    "fig_two = '''$PYTHON /tools/mixer/precimed/mixer_figures.py two \\\n",
    "    --json-fit {output_dir}/{trait0}_vs_{trait1}.fit.json \\\n",
    "    --json-test {output_dir}/{trait0}_vs_{trait1}.test.json \\\n",
    "    --out {output_dir}/{trait0}_vs_{trait1} --trait1 {trait0} --trait2 {trait1} \\\n",
    "    --statistic mean std --ext {ext}'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb8e74da",
   "metadata": {},
   "source": [
    "### Create and submit jobscripts with handling of job dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61146690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit1\n",
    "fit1_job_ids = dict()\n",
    "for trait, fname in {**primary_traits, **secondary_traits}.items():\n",
    "    traitfile = os.path.join(sumstats_mixer, fname)\n",
    "    assert os.path.isfile(traitfile), f'file {traitfile} is missing'\n",
    "    \n",
    "    # write job file\n",
    "    dt = datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")\n",
    "    logfile = os.path.join(logs_dir, f'mixer_fit1_{trait}_{dt}_%A_%a.txt')\n",
    "    jobscript = slurm_header.format(job_name=f'mixer_fit1_{trait}',\n",
    "                                    account=account,\n",
    "                                    mixer_dir=mixer_dir,\n",
    "                                    singularity_module=singularity_module,\n",
    "                                    log_file=logfile, \n",
    "                                    time='07:00:00', \n",
    "                                    cpus_per_task=cpus_per_task, \n",
    "                                    mem_per_cpu=mem_per_cpu,\n",
    "                                    array=array)\n",
    "    jobscript += fit1.format(traitfile, output_dir, trait)\n",
    "    fjob = os.path.join(jobscripts_dir, f'mixer_fit1_{trait}.job')\n",
    "    with open(fjob, 'w') as f:\n",
    "        f.writelines(jobscript)\n",
    "    \n",
    "    # submit job\n",
    "    cmd = ' '.join(['sbatch', fjob])\n",
    "    print(cmd)\n",
    "    output = sp.getoutput(cmd)\n",
    "    jobid = output.split(' ')[-1]\n",
    "    fit1_job_ids.update({f'mixer_fit1_{trait}': jobid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1\n",
    "test1_job_ids = dict()\n",
    "for trait, fname in {**primary_traits, **secondary_traits}.items():\n",
    "    traitfile = os.path.join(sumstats_mixer, fname)\n",
    "    assert os.path.isfile(traitfile), f'file {traitfile} is missing'\n",
    "    \n",
    "    # write job file\n",
    "    dt = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    logfile = os.path.join(logs_dir, f'mixer_test1_{trait}_{dt}_%A_%a.txt')\n",
    "    jobscript = slurm_header.format(job_name=f'mixer_test1_{trait}_{dt}', \n",
    "                                    account=account,\n",
    "                                    mixer_dir=mixer_dir,\n",
    "                                    singularity_module=singularity_module,\n",
    "                                    log_file=logfile, \n",
    "                                    time='01:00:00', \n",
    "                                    cpus_per_task=cpus_per_task, \n",
    "                                    mem_per_cpu=mem_per_cpu,\n",
    "                                    array=array)\n",
    "    jobscript += test1.format(traitfile, output_dir, trait, output_dir, trait)\n",
    "    fjob = os.path.join(jobscripts_dir, f'mixer_test1_{trait}.job')\n",
    "    with open(fjob, 'w') as f:\n",
    "        f.writelines(jobscript)\n",
    "    \n",
    "    # get job dependency\n",
    "    jobdep = fit1_job_ids[f'mixer_fit1_{trait}']\n",
    "    \n",
    "    # submit job\n",
    "    cmd = ' '.join(['sbatch', f'--dependency=afterok:{jobdep}', fjob])\n",
    "    print(cmd, f'; depends on {jobdep}')\n",
    "    output = sp.getoutput(cmd)\n",
    "    jobid = output.split(' ')[-1]\n",
    "    test1_job_ids.update({f'mixer_test1_{trait}': jobid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit2\n",
    "fit2_job_ids = dict()\n",
    "for trait0, fname0 in secondary_traits.items():\n",
    "    traitfile0 = os.path.join(sumstats_mixer, fname0)\n",
    "    for trait1, fname1 in primary_traits.items():\n",
    "        if fname0 == fname1:\n",
    "            continue\n",
    "        traitfile1 = os.path.join(sumstats_mixer, fname1)\n",
    "    \n",
    "        # write job file\n",
    "        jobname = f'mixer_fit2_{trait0}_vs_{trait1}'\n",
    "        dt = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "        logfile = os.path.join(logs_dir, f'{jobname}_{dt}_%A_%a.txt')\n",
    "        jobscript = slurm_header.format(job_name=jobname, \n",
    "                                        account=account,\n",
    "                                        mixer_dir=mixer_dir,\n",
    "                                        singularity_module=singularity_module,\n",
    "                                        log_file=logfile, \n",
    "                                        time='05:00:00', \n",
    "                                        cpus_per_task=cpus_per_task, \n",
    "                                        mem_per_cpu=mem_per_cpu,\n",
    "                                        array=array)\n",
    "        jobscript += fit2.format(traitfile0, traitfile1, \n",
    "                       output_dir, trait0, \n",
    "                       output_dir, trait1, \n",
    "                       output_dir, trait0, trait1)\n",
    "        fjob = os.path.join(jobscripts_dir, f'mixer_fit2_{trait0}_vs_{trait1}.job')\n",
    "        with open(fjob, 'w') as f:\n",
    "            f.writelines(jobscript)\n",
    "\n",
    "        # get job dependencies\n",
    "        jobdeps = [fit1_job_ids[f'mixer_fit1_{trait0}'], \n",
    "                   fit1_job_ids[f'mixer_fit1_{trait1}'],\n",
    "                   test1_job_ids[f'mixer_test1_{trait0}'],\n",
    "                   test1_job_ids[f'mixer_test1_{trait1}'],\n",
    "                   ]\n",
    "        \n",
    "        # submit job and get job ID:\n",
    "        cmd = ' '.join(['sbatch',\n",
    "                        '--dependency=afterok:{}'.format(','.join(jobdeps)),\n",
    "                        fjob])\n",
    "        print(cmd, f'; depends on {\",\".join(jobdeps)}')\n",
    "        output = sp.getoutput(cmd)\n",
    "        jobid = output.split(' ')[-1]\n",
    "        fit2_job_ids.update({f'mixer_fit2_{trait0}_vs_{trait1}': jobid})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae62851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2\n",
    "test2_job_ids = dict()\n",
    "for trait0, fname0 in secondary_traits.items():\n",
    "    traitfile0 = os.path.join(sumstats_mixer, fname0)\n",
    "    for trait1, fname1 in primary_traits.items():\n",
    "        if fname0 == fname1:\n",
    "            continue\n",
    "        traitfile1 = os.path.join(sumstats_mixer, fname1)\n",
    "    \n",
    "        # write job file\n",
    "        jobname = f'mixer_test2_{trait0}_vs_{trait1}'\n",
    "        dt = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "        logfile = os.path.join(logs_dir, f'{jobname}_{dt}_%A_%a.txt')\n",
    "\n",
    "        jobscript = slurm_header.format(job_name=jobname, \n",
    "                                        account=account,\n",
    "                                        mixer_dir=mixer_dir,\n",
    "                                        singularity_module=singularity_module,\n",
    "                                        log_file=logfile, \n",
    "                                        time='02:00:00', \n",
    "                                        cpus_per_task=cpus_per_task, \n",
    "                                        mem_per_cpu=mem_per_cpu,\n",
    "                                        array=array)\n",
    "        \n",
    "        jobscript += test2.format(traitfile0, traitfile1, \n",
    "                       output_dir, trait0, trait1,\n",
    "                       output_dir, trait0, trait1)\n",
    "        fjob = os.path.join(jobscripts_dir, f'mixer_test2_{trait0}_vs_{trait1}.job')\n",
    "        with open(fjob, 'w') as f:\n",
    "            f.writelines(jobscript)\n",
    "\n",
    "        # get job dependencies\n",
    "        jobdeps = [fit2_job_ids[f'mixer_fit2_{trait0}_vs_{trait1}']\n",
    "        ]\n",
    "        \n",
    "        # submit job and get job ID:\n",
    "        cmd = ' '.join(['sbatch',\n",
    "                        '--dependency=afterok:{}'.format(','.join(jobdeps)),\n",
    "                        fjob])\n",
    "        print(cmd, f'; depends on {\",\".join(jobdeps)}')\n",
    "        output = sp.getoutput(cmd)\n",
    "        jobid = output.split(' ')[-1]\n",
    "        test2_job_ids.update({f'mixer_test2_{trait0}_vs_{trait1}': jobid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751030d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write plotting job file\n",
    "jobname = 'mixer_plots'\n",
    "dt = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "logfile = os.path.join(logs_dir, f'{jobname}_{dt}_%A_%a.txt')\n",
    "jobscript = slurm_header.format(job_name=jobname, \n",
    "                                account=account,\n",
    "                                mixer_dir=mixer_dir,\n",
    "                                singularity_module=singularity_module,\n",
    "                                log_file=logfile, \n",
    "                                time='01:00:00', \n",
    "                                cpus_per_task=2, \n",
    "                                mem_per_cpu=mem_per_cpu,\n",
    "                                array='1')\n",
    "fjob = os.path.join(jobscripts_dir, f'{jobname}.job')\n",
    "\n",
    "# job script content\n",
    "tasklist = []\n",
    "\n",
    "# combine1\n",
    "tasklist += ['# combine univariate'] \n",
    "for fit_or_test in ['fit', 'test']:\n",
    "    for trait in {**primary_traits, **secondary_traits}.keys():\n",
    "        tasklist += [combine1.format(output_dir=output_dir, \n",
    "                                     trait=trait, \n",
    "                                     fit_or_test=fit_or_test)]\n",
    "    tasklist += ['\\n']\n",
    "\n",
    "# combine2\n",
    "tasklist += ['# combine bivariate'] \n",
    "for fit_or_test in ['fit', 'test']:\n",
    "    for trait0 in secondary_traits.keys():\n",
    "        for trait1 in primary_traits.keys():\n",
    "            if trait0 == trait1:\n",
    "                continue\n",
    "            tasklist += [combine2.format(output_dir=output_dir, \n",
    "                                         trait0=trait0, \n",
    "                                         trait1=trait1, \n",
    "                                         fit_or_test=fit_or_test)]\n",
    "    tasklist += ['\\n']\n",
    "\n",
    "# fig_one\n",
    "tasklist += ['# mixer_figure one'] \n",
    "for fit_or_test in ['fit', 'test']:\n",
    "    for trait0 in secondary_traits.keys():\n",
    "        for trait1 in primary_traits.keys():\n",
    "            if trait0 == trait1:\n",
    "                continue\n",
    "            for ext in ['png', 'svg']:\n",
    "                tasklist += [fig_one.format(output_dir=output_dir, \n",
    "                               trait0=trait0, \n",
    "                               trait1=trait1, \n",
    "                               fit_or_test=fit_or_test, \n",
    "                               ext=ext)]\n",
    "tasklist += ['\\n']\n",
    "\n",
    "# fig_two\n",
    "tasklist += ['# mixer_figure two'] \n",
    "for trait0 in secondary_traits.keys():\n",
    "    for trait1 in primary_traits.keys():\n",
    "        if trait0 == trait1:\n",
    "            continue\n",
    "        for ext in ['png', 'svg']:\n",
    "            tasklist += [fig_two.format(output_dir=output_dir, \n",
    "                           trait0=trait0, \n",
    "                           trait1=trait1, \n",
    "                           ext=ext)]\n",
    "tasklist += ['\\n']\n",
    "\n",
    "with open(fjob, 'w') as f:\n",
    "    f.writelines(jobscript + '\\n'.join(tasklist))\n",
    "\n",
    "\n",
    "# get job dependencies\n",
    "jobdeps = []\n",
    "for trait0 in secondary_traits.keys():\n",
    "    for trait1 in primary_traits.keys():\n",
    "        if trait0 == trait1:\n",
    "            continue\n",
    "        jobdeps += [test2_job_ids[f'mixer_test2_{trait0}_vs_{trait1}']]\n",
    "if len(jobdeps) == 0:\n",
    "    cmd = ' '.join(['sbatch', fjob])\n",
    "    print(cmd)\n",
    "else:    \n",
    "    cmd = ' '.join(['sbatch',\n",
    "                    '--dependency=afterok:{}'.format(','.join(jobdeps)),\n",
    "                    fjob])\n",
    "    print(cmd, f'; depends on {\",\".join(jobdeps)}')\n",
    "\n",
    "output = sp.getoutput(cmd)\n",
    "jobid = output.split(' ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to check the status of submitted jobs\n",
    "# !squeue -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beede6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to check that there are no errors in logs (like missing output files):\n",
    "# !grep rror logs/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec385ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
